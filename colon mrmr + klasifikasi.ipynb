{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/colonTumor.csv\")\n",
    "data_length = data.shape[1]\n",
    "data_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = []\n",
    "for i in range(data_length):\n",
    "    column.append(\"atribut\"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atribut0</th>\n",
       "      <th>atribut1</th>\n",
       "      <th>atribut2</th>\n",
       "      <th>atribut3</th>\n",
       "      <th>atribut4</th>\n",
       "      <th>atribut5</th>\n",
       "      <th>atribut6</th>\n",
       "      <th>atribut7</th>\n",
       "      <th>atribut8</th>\n",
       "      <th>atribut9</th>\n",
       "      <th>...</th>\n",
       "      <th>atribut1991</th>\n",
       "      <th>atribut1992</th>\n",
       "      <th>atribut1993</th>\n",
       "      <th>atribut1994</th>\n",
       "      <th>atribut1995</th>\n",
       "      <th>atribut1996</th>\n",
       "      <th>atribut1997</th>\n",
       "      <th>atribut1998</th>\n",
       "      <th>atribut1999</th>\n",
       "      <th>atribut2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8589.4163</td>\n",
       "      <td>5468.2409</td>\n",
       "      <td>4263.4075</td>\n",
       "      <td>4064.9357</td>\n",
       "      <td>1997.8929</td>\n",
       "      <td>5282.3250</td>\n",
       "      <td>2169.7200</td>\n",
       "      <td>2773.4212</td>\n",
       "      <td>7526.3862</td>\n",
       "      <td>4607.6762</td>\n",
       "      <td>...</td>\n",
       "      <td>67.56125</td>\n",
       "      <td>259.91250</td>\n",
       "      <td>138.89875</td>\n",
       "      <td>88.23250</td>\n",
       "      <td>39.667857</td>\n",
       "      <td>67.82875</td>\n",
       "      <td>75.67750</td>\n",
       "      <td>83.52250</td>\n",
       "      <td>28.70125</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9164.2537</td>\n",
       "      <td>6719.5295</td>\n",
       "      <td>4883.4487</td>\n",
       "      <td>3718.1589</td>\n",
       "      <td>2015.2214</td>\n",
       "      <td>5569.9071</td>\n",
       "      <td>3849.0588</td>\n",
       "      <td>2793.3875</td>\n",
       "      <td>7017.7338</td>\n",
       "      <td>4802.2524</td>\n",
       "      <td>...</td>\n",
       "      <td>92.23875</td>\n",
       "      <td>96.27625</td>\n",
       "      <td>150.59000</td>\n",
       "      <td>82.23750</td>\n",
       "      <td>85.033333</td>\n",
       "      <td>152.19500</td>\n",
       "      <td>186.56750</td>\n",
       "      <td>44.47250</td>\n",
       "      <td>16.77375</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3825.7050</td>\n",
       "      <td>6970.3614</td>\n",
       "      <td>5369.9688</td>\n",
       "      <td>4705.6500</td>\n",
       "      <td>1166.5536</td>\n",
       "      <td>1572.1679</td>\n",
       "      <td>1325.4025</td>\n",
       "      <td>1472.2587</td>\n",
       "      <td>3296.9512</td>\n",
       "      <td>2786.5821</td>\n",
       "      <td>...</td>\n",
       "      <td>82.71500</td>\n",
       "      <td>31.10250</td>\n",
       "      <td>193.92000</td>\n",
       "      <td>76.97250</td>\n",
       "      <td>224.620240</td>\n",
       "      <td>31.22500</td>\n",
       "      <td>42.65625</td>\n",
       "      <td>16.09250</td>\n",
       "      <td>15.15625</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6246.4487</td>\n",
       "      <td>7823.5341</td>\n",
       "      <td>5955.8350</td>\n",
       "      <td>3975.5643</td>\n",
       "      <td>2002.6131</td>\n",
       "      <td>2130.5429</td>\n",
       "      <td>1531.1425</td>\n",
       "      <td>1714.6312</td>\n",
       "      <td>3869.7850</td>\n",
       "      <td>4989.4071</td>\n",
       "      <td>...</td>\n",
       "      <td>41.68375</td>\n",
       "      <td>5.92500</td>\n",
       "      <td>183.00625</td>\n",
       "      <td>74.52875</td>\n",
       "      <td>67.710714</td>\n",
       "      <td>48.33875</td>\n",
       "      <td>42.52000</td>\n",
       "      <td>49.98250</td>\n",
       "      <td>16.08500</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3230.3287</td>\n",
       "      <td>3694.4500</td>\n",
       "      <td>3400.7400</td>\n",
       "      <td>3463.5857</td>\n",
       "      <td>2181.4202</td>\n",
       "      <td>2922.7821</td>\n",
       "      <td>2069.2463</td>\n",
       "      <td>2948.5750</td>\n",
       "      <td>3303.3712</td>\n",
       "      <td>3109.4131</td>\n",
       "      <td>...</td>\n",
       "      <td>76.60375</td>\n",
       "      <td>161.35000</td>\n",
       "      <td>61.70125</td>\n",
       "      <td>54.56375</td>\n",
       "      <td>223.359520</td>\n",
       "      <td>73.09875</td>\n",
       "      <td>57.59875</td>\n",
       "      <td>7.48875</td>\n",
       "      <td>31.81250</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    atribut0   atribut1   atribut2   atribut3   atribut4   atribut5  \\\n",
       "0  8589.4163  5468.2409  4263.4075  4064.9357  1997.8929  5282.3250   \n",
       "1  9164.2537  6719.5295  4883.4487  3718.1589  2015.2214  5569.9071   \n",
       "2  3825.7050  6970.3614  5369.9688  4705.6500  1166.5536  1572.1679   \n",
       "3  6246.4487  7823.5341  5955.8350  3975.5643  2002.6131  2130.5429   \n",
       "4  3230.3287  3694.4500  3400.7400  3463.5857  2181.4202  2922.7821   \n",
       "\n",
       "    atribut6   atribut7   atribut8   atribut9  ...  atribut1991  atribut1992  \\\n",
       "0  2169.7200  2773.4212  7526.3862  4607.6762  ...     67.56125    259.91250   \n",
       "1  3849.0588  2793.3875  7017.7338  4802.2524  ...     92.23875     96.27625   \n",
       "2  1325.4025  1472.2587  3296.9512  2786.5821  ...     82.71500     31.10250   \n",
       "3  1531.1425  1714.6312  3869.7850  4989.4071  ...     41.68375      5.92500   \n",
       "4  2069.2463  2948.5750  3303.3712  3109.4131  ...     76.60375    161.35000   \n",
       "\n",
       "   atribut1993  atribut1994  atribut1995  atribut1996  atribut1997  \\\n",
       "0    138.89875     88.23250    39.667857     67.82875     75.67750   \n",
       "1    150.59000     82.23750    85.033333    152.19500    186.56750   \n",
       "2    193.92000     76.97250   224.620240     31.22500     42.65625   \n",
       "3    183.00625     74.52875    67.710714     48.33875     42.52000   \n",
       "4     61.70125     54.56375   223.359520     73.09875     57.59875   \n",
       "\n",
       "   atribut1998  atribut1999  atribut2000  \n",
       "0     83.52250     28.70125     negative  \n",
       "1     44.47250     16.77375     positive  \n",
       "2     16.09250     15.15625     negative  \n",
       "3     49.98250     16.08500     positive  \n",
       "4      7.48875     31.81250     negative  \n",
       "\n",
       "[5 rows x 2001 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/colonTumor.csv\", header=None, names=column)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atribut0</th>\n",
       "      <th>atribut1</th>\n",
       "      <th>atribut2</th>\n",
       "      <th>atribut3</th>\n",
       "      <th>atribut4</th>\n",
       "      <th>atribut5</th>\n",
       "      <th>atribut6</th>\n",
       "      <th>atribut7</th>\n",
       "      <th>atribut8</th>\n",
       "      <th>atribut9</th>\n",
       "      <th>...</th>\n",
       "      <th>atribut1991</th>\n",
       "      <th>atribut1992</th>\n",
       "      <th>atribut1993</th>\n",
       "      <th>atribut1994</th>\n",
       "      <th>atribut1995</th>\n",
       "      <th>atribut1996</th>\n",
       "      <th>atribut1997</th>\n",
       "      <th>atribut1998</th>\n",
       "      <th>atribut1999</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8589.4163</td>\n",
       "      <td>5468.2409</td>\n",
       "      <td>4263.4075</td>\n",
       "      <td>4064.9357</td>\n",
       "      <td>1997.8929</td>\n",
       "      <td>5282.3250</td>\n",
       "      <td>2169.7200</td>\n",
       "      <td>2773.4212</td>\n",
       "      <td>7526.3862</td>\n",
       "      <td>4607.6762</td>\n",
       "      <td>...</td>\n",
       "      <td>67.56125</td>\n",
       "      <td>259.91250</td>\n",
       "      <td>138.89875</td>\n",
       "      <td>88.23250</td>\n",
       "      <td>39.667857</td>\n",
       "      <td>67.82875</td>\n",
       "      <td>75.67750</td>\n",
       "      <td>83.52250</td>\n",
       "      <td>28.70125</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9164.2537</td>\n",
       "      <td>6719.5295</td>\n",
       "      <td>4883.4487</td>\n",
       "      <td>3718.1589</td>\n",
       "      <td>2015.2214</td>\n",
       "      <td>5569.9071</td>\n",
       "      <td>3849.0588</td>\n",
       "      <td>2793.3875</td>\n",
       "      <td>7017.7338</td>\n",
       "      <td>4802.2524</td>\n",
       "      <td>...</td>\n",
       "      <td>92.23875</td>\n",
       "      <td>96.27625</td>\n",
       "      <td>150.59000</td>\n",
       "      <td>82.23750</td>\n",
       "      <td>85.033333</td>\n",
       "      <td>152.19500</td>\n",
       "      <td>186.56750</td>\n",
       "      <td>44.47250</td>\n",
       "      <td>16.77375</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3825.7050</td>\n",
       "      <td>6970.3614</td>\n",
       "      <td>5369.9688</td>\n",
       "      <td>4705.6500</td>\n",
       "      <td>1166.5536</td>\n",
       "      <td>1572.1679</td>\n",
       "      <td>1325.4025</td>\n",
       "      <td>1472.2587</td>\n",
       "      <td>3296.9512</td>\n",
       "      <td>2786.5821</td>\n",
       "      <td>...</td>\n",
       "      <td>82.71500</td>\n",
       "      <td>31.10250</td>\n",
       "      <td>193.92000</td>\n",
       "      <td>76.97250</td>\n",
       "      <td>224.620240</td>\n",
       "      <td>31.22500</td>\n",
       "      <td>42.65625</td>\n",
       "      <td>16.09250</td>\n",
       "      <td>15.15625</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6246.4487</td>\n",
       "      <td>7823.5341</td>\n",
       "      <td>5955.8350</td>\n",
       "      <td>3975.5643</td>\n",
       "      <td>2002.6131</td>\n",
       "      <td>2130.5429</td>\n",
       "      <td>1531.1425</td>\n",
       "      <td>1714.6312</td>\n",
       "      <td>3869.7850</td>\n",
       "      <td>4989.4071</td>\n",
       "      <td>...</td>\n",
       "      <td>41.68375</td>\n",
       "      <td>5.92500</td>\n",
       "      <td>183.00625</td>\n",
       "      <td>74.52875</td>\n",
       "      <td>67.710714</td>\n",
       "      <td>48.33875</td>\n",
       "      <td>42.52000</td>\n",
       "      <td>49.98250</td>\n",
       "      <td>16.08500</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3230.3287</td>\n",
       "      <td>3694.4500</td>\n",
       "      <td>3400.7400</td>\n",
       "      <td>3463.5857</td>\n",
       "      <td>2181.4202</td>\n",
       "      <td>2922.7821</td>\n",
       "      <td>2069.2463</td>\n",
       "      <td>2948.5750</td>\n",
       "      <td>3303.3712</td>\n",
       "      <td>3109.4131</td>\n",
       "      <td>...</td>\n",
       "      <td>76.60375</td>\n",
       "      <td>161.35000</td>\n",
       "      <td>61.70125</td>\n",
       "      <td>54.56375</td>\n",
       "      <td>223.359520</td>\n",
       "      <td>73.09875</td>\n",
       "      <td>57.59875</td>\n",
       "      <td>7.48875</td>\n",
       "      <td>31.81250</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    atribut0   atribut1   atribut2   atribut3   atribut4   atribut5  \\\n",
       "0  8589.4163  5468.2409  4263.4075  4064.9357  1997.8929  5282.3250   \n",
       "1  9164.2537  6719.5295  4883.4487  3718.1589  2015.2214  5569.9071   \n",
       "2  3825.7050  6970.3614  5369.9688  4705.6500  1166.5536  1572.1679   \n",
       "3  6246.4487  7823.5341  5955.8350  3975.5643  2002.6131  2130.5429   \n",
       "4  3230.3287  3694.4500  3400.7400  3463.5857  2181.4202  2922.7821   \n",
       "\n",
       "    atribut6   atribut7   atribut8   atribut9  ...  atribut1991  atribut1992  \\\n",
       "0  2169.7200  2773.4212  7526.3862  4607.6762  ...     67.56125    259.91250   \n",
       "1  3849.0588  2793.3875  7017.7338  4802.2524  ...     92.23875     96.27625   \n",
       "2  1325.4025  1472.2587  3296.9512  2786.5821  ...     82.71500     31.10250   \n",
       "3  1531.1425  1714.6312  3869.7850  4989.4071  ...     41.68375      5.92500   \n",
       "4  2069.2463  2948.5750  3303.3712  3109.4131  ...     76.60375    161.35000   \n",
       "\n",
       "   atribut1993  atribut1994  atribut1995  atribut1996  atribut1997  \\\n",
       "0    138.89875     88.23250    39.667857     67.82875     75.67750   \n",
       "1    150.59000     82.23750    85.033333    152.19500    186.56750   \n",
       "2    193.92000     76.97250   224.620240     31.22500     42.65625   \n",
       "3    183.00625     74.52875    67.710714     48.33875     42.52000   \n",
       "4     61.70125     54.56375   223.359520     73.09875     57.59875   \n",
       "\n",
       "   atribut1998  atribut1999    status  \n",
       "0     83.52250     28.70125  negative  \n",
       "1     44.47250     16.77375  positive  \n",
       "2     16.09250     15.15625  negative  \n",
       "3     49.98250     16.08500  positive  \n",
       "4      7.48875     31.81250  negative  \n",
       "\n",
       "[5 rows x 2001 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.rename(columns={'atribut2000': 'status'})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atribut0</th>\n",
       "      <th>atribut1</th>\n",
       "      <th>atribut2</th>\n",
       "      <th>atribut3</th>\n",
       "      <th>atribut4</th>\n",
       "      <th>atribut5</th>\n",
       "      <th>atribut6</th>\n",
       "      <th>atribut7</th>\n",
       "      <th>atribut8</th>\n",
       "      <th>atribut9</th>\n",
       "      <th>...</th>\n",
       "      <th>atribut1991</th>\n",
       "      <th>atribut1992</th>\n",
       "      <th>atribut1993</th>\n",
       "      <th>atribut1994</th>\n",
       "      <th>atribut1995</th>\n",
       "      <th>atribut1996</th>\n",
       "      <th>atribut1997</th>\n",
       "      <th>atribut1998</th>\n",
       "      <th>atribut1999</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8589.4163</td>\n",
       "      <td>5468.2409</td>\n",
       "      <td>4263.4075</td>\n",
       "      <td>4064.9357</td>\n",
       "      <td>1997.8929</td>\n",
       "      <td>5282.3250</td>\n",
       "      <td>2169.7200</td>\n",
       "      <td>2773.4212</td>\n",
       "      <td>7526.3862</td>\n",
       "      <td>4607.6762</td>\n",
       "      <td>...</td>\n",
       "      <td>67.56125</td>\n",
       "      <td>259.91250</td>\n",
       "      <td>138.89875</td>\n",
       "      <td>88.23250</td>\n",
       "      <td>39.667857</td>\n",
       "      <td>67.82875</td>\n",
       "      <td>75.67750</td>\n",
       "      <td>83.52250</td>\n",
       "      <td>28.70125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9164.2537</td>\n",
       "      <td>6719.5295</td>\n",
       "      <td>4883.4487</td>\n",
       "      <td>3718.1589</td>\n",
       "      <td>2015.2214</td>\n",
       "      <td>5569.9071</td>\n",
       "      <td>3849.0588</td>\n",
       "      <td>2793.3875</td>\n",
       "      <td>7017.7338</td>\n",
       "      <td>4802.2524</td>\n",
       "      <td>...</td>\n",
       "      <td>92.23875</td>\n",
       "      <td>96.27625</td>\n",
       "      <td>150.59000</td>\n",
       "      <td>82.23750</td>\n",
       "      <td>85.033333</td>\n",
       "      <td>152.19500</td>\n",
       "      <td>186.56750</td>\n",
       "      <td>44.47250</td>\n",
       "      <td>16.77375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3825.7050</td>\n",
       "      <td>6970.3614</td>\n",
       "      <td>5369.9688</td>\n",
       "      <td>4705.6500</td>\n",
       "      <td>1166.5536</td>\n",
       "      <td>1572.1679</td>\n",
       "      <td>1325.4025</td>\n",
       "      <td>1472.2587</td>\n",
       "      <td>3296.9512</td>\n",
       "      <td>2786.5821</td>\n",
       "      <td>...</td>\n",
       "      <td>82.71500</td>\n",
       "      <td>31.10250</td>\n",
       "      <td>193.92000</td>\n",
       "      <td>76.97250</td>\n",
       "      <td>224.620240</td>\n",
       "      <td>31.22500</td>\n",
       "      <td>42.65625</td>\n",
       "      <td>16.09250</td>\n",
       "      <td>15.15625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6246.4487</td>\n",
       "      <td>7823.5341</td>\n",
       "      <td>5955.8350</td>\n",
       "      <td>3975.5643</td>\n",
       "      <td>2002.6131</td>\n",
       "      <td>2130.5429</td>\n",
       "      <td>1531.1425</td>\n",
       "      <td>1714.6312</td>\n",
       "      <td>3869.7850</td>\n",
       "      <td>4989.4071</td>\n",
       "      <td>...</td>\n",
       "      <td>41.68375</td>\n",
       "      <td>5.92500</td>\n",
       "      <td>183.00625</td>\n",
       "      <td>74.52875</td>\n",
       "      <td>67.710714</td>\n",
       "      <td>48.33875</td>\n",
       "      <td>42.52000</td>\n",
       "      <td>49.98250</td>\n",
       "      <td>16.08500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3230.3287</td>\n",
       "      <td>3694.4500</td>\n",
       "      <td>3400.7400</td>\n",
       "      <td>3463.5857</td>\n",
       "      <td>2181.4202</td>\n",
       "      <td>2922.7821</td>\n",
       "      <td>2069.2463</td>\n",
       "      <td>2948.5750</td>\n",
       "      <td>3303.3712</td>\n",
       "      <td>3109.4131</td>\n",
       "      <td>...</td>\n",
       "      <td>76.60375</td>\n",
       "      <td>161.35000</td>\n",
       "      <td>61.70125</td>\n",
       "      <td>54.56375</td>\n",
       "      <td>223.359520</td>\n",
       "      <td>73.09875</td>\n",
       "      <td>57.59875</td>\n",
       "      <td>7.48875</td>\n",
       "      <td>31.81250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    atribut0   atribut1   atribut2   atribut3   atribut4   atribut5  \\\n",
       "0  8589.4163  5468.2409  4263.4075  4064.9357  1997.8929  5282.3250   \n",
       "1  9164.2537  6719.5295  4883.4487  3718.1589  2015.2214  5569.9071   \n",
       "2  3825.7050  6970.3614  5369.9688  4705.6500  1166.5536  1572.1679   \n",
       "3  6246.4487  7823.5341  5955.8350  3975.5643  2002.6131  2130.5429   \n",
       "4  3230.3287  3694.4500  3400.7400  3463.5857  2181.4202  2922.7821   \n",
       "\n",
       "    atribut6   atribut7   atribut8   atribut9  ...  atribut1991  atribut1992  \\\n",
       "0  2169.7200  2773.4212  7526.3862  4607.6762  ...     67.56125    259.91250   \n",
       "1  3849.0588  2793.3875  7017.7338  4802.2524  ...     92.23875     96.27625   \n",
       "2  1325.4025  1472.2587  3296.9512  2786.5821  ...     82.71500     31.10250   \n",
       "3  1531.1425  1714.6312  3869.7850  4989.4071  ...     41.68375      5.92500   \n",
       "4  2069.2463  2948.5750  3303.3712  3109.4131  ...     76.60375    161.35000   \n",
       "\n",
       "   atribut1993  atribut1994  atribut1995  atribut1996  atribut1997  \\\n",
       "0    138.89875     88.23250    39.667857     67.82875     75.67750   \n",
       "1    150.59000     82.23750    85.033333    152.19500    186.56750   \n",
       "2    193.92000     76.97250   224.620240     31.22500     42.65625   \n",
       "3    183.00625     74.52875    67.710714     48.33875     42.52000   \n",
       "4     61.70125     54.56375   223.359520     73.09875     57.59875   \n",
       "\n",
       "   atribut1998  atribut1999  status  \n",
       "0     83.52250     28.70125       0  \n",
       "1     44.47250     16.77375       1  \n",
       "2     16.09250     15.15625       0  \n",
       "3     49.98250     16.08500       1  \n",
       "4      7.48875     31.81250       0  \n",
       "\n",
       "[5 rows x 2001 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['status'] == 'negative', ['status']] = 0\n",
    "data.loc[data['status'] == 'positive', ['status']] = 1\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    40\n",
       "1    22\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data['status'].value_counts().plot(kind='bar', color=\"b\")\n",
    "plt.title(\"Perbandingan jumlah negative dan positif\")\n",
    "plt.xlabel('Status')\n",
    "plt.ylabel('Total')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atribut0</th>\n",
       "      <th>atribut1</th>\n",
       "      <th>atribut2</th>\n",
       "      <th>atribut3</th>\n",
       "      <th>atribut4</th>\n",
       "      <th>atribut5</th>\n",
       "      <th>atribut6</th>\n",
       "      <th>atribut7</th>\n",
       "      <th>atribut8</th>\n",
       "      <th>atribut9</th>\n",
       "      <th>...</th>\n",
       "      <th>atribut1991</th>\n",
       "      <th>atribut1992</th>\n",
       "      <th>atribut1993</th>\n",
       "      <th>atribut1994</th>\n",
       "      <th>atribut1995</th>\n",
       "      <th>atribut1996</th>\n",
       "      <th>atribut1997</th>\n",
       "      <th>atribut1998</th>\n",
       "      <th>atribut1999</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>7015.786710</td>\n",
       "      <td>4966.960015</td>\n",
       "      <td>4094.727879</td>\n",
       "      <td>3987.789284</td>\n",
       "      <td>2937.126113</td>\n",
       "      <td>4705.119302</td>\n",
       "      <td>3588.800323</td>\n",
       "      <td>2872.288631</td>\n",
       "      <td>4680.191160</td>\n",
       "      <td>4039.661953</td>\n",
       "      <td>...</td>\n",
       "      <td>100.227903</td>\n",
       "      <td>293.222722</td>\n",
       "      <td>124.653387</td>\n",
       "      <td>133.186935</td>\n",
       "      <td>184.136635</td>\n",
       "      <td>84.118387</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>53.251230</td>\n",
       "      <td>42.965827</td>\n",
       "      <td>0.354839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>3092.970584</td>\n",
       "      <td>2188.890480</td>\n",
       "      <td>1818.080939</td>\n",
       "      <td>2019.086903</td>\n",
       "      <td>1356.932887</td>\n",
       "      <td>2400.848112</td>\n",
       "      <td>1872.106095</td>\n",
       "      <td>1122.365448</td>\n",
       "      <td>2417.239217</td>\n",
       "      <td>2018.044248</td>\n",
       "      <td>...</td>\n",
       "      <td>78.022712</td>\n",
       "      <td>179.249194</td>\n",
       "      <td>75.535838</td>\n",
       "      <td>101.372557</td>\n",
       "      <td>159.914871</td>\n",
       "      <td>86.182028</td>\n",
       "      <td>88.011866</td>\n",
       "      <td>38.462814</td>\n",
       "      <td>28.395175</td>\n",
       "      <td>0.482370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1914.677500</td>\n",
       "      <td>1383.488600</td>\n",
       "      <td>1269.648700</td>\n",
       "      <td>1186.030400</td>\n",
       "      <td>1166.553600</td>\n",
       "      <td>1087.750000</td>\n",
       "      <td>1062.697500</td>\n",
       "      <td>1026.477500</td>\n",
       "      <td>995.790000</td>\n",
       "      <td>974.815480</td>\n",
       "      <td>...</td>\n",
       "      <td>5.935000</td>\n",
       "      <td>5.925000</td>\n",
       "      <td>5.923750</td>\n",
       "      <td>5.916250</td>\n",
       "      <td>5.888095</td>\n",
       "      <td>5.878750</td>\n",
       "      <td>5.848750</td>\n",
       "      <td>5.842500</td>\n",
       "      <td>5.816250</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>4877.364700</td>\n",
       "      <td>3408.951150</td>\n",
       "      <td>2763.725900</td>\n",
       "      <td>2648.942875</td>\n",
       "      <td>1890.857125</td>\n",
       "      <td>2843.368775</td>\n",
       "      <td>2112.952150</td>\n",
       "      <td>2050.814025</td>\n",
       "      <td>2971.792775</td>\n",
       "      <td>2797.992525</td>\n",
       "      <td>...</td>\n",
       "      <td>48.409375</td>\n",
       "      <td>161.518125</td>\n",
       "      <td>69.121250</td>\n",
       "      <td>71.637500</td>\n",
       "      <td>85.905059</td>\n",
       "      <td>30.701875</td>\n",
       "      <td>53.881563</td>\n",
       "      <td>27.334375</td>\n",
       "      <td>24.610000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>6274.612500</td>\n",
       "      <td>4738.280700</td>\n",
       "      <td>3890.338100</td>\n",
       "      <td>3451.498200</td>\n",
       "      <td>2666.075600</td>\n",
       "      <td>4416.617850</td>\n",
       "      <td>3438.180000</td>\n",
       "      <td>2844.960650</td>\n",
       "      <td>4088.735600</td>\n",
       "      <td>3823.017900</td>\n",
       "      <td>...</td>\n",
       "      <td>83.080625</td>\n",
       "      <td>251.883125</td>\n",
       "      <td>114.658125</td>\n",
       "      <td>104.271875</td>\n",
       "      <td>142.578570</td>\n",
       "      <td>56.385625</td>\n",
       "      <td>93.825625</td>\n",
       "      <td>45.358125</td>\n",
       "      <td>34.775000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>8712.283175</td>\n",
       "      <td>6455.843200</td>\n",
       "      <td>5008.993750</td>\n",
       "      <td>4738.408950</td>\n",
       "      <td>3563.969325</td>\n",
       "      <td>6076.032125</td>\n",
       "      <td>4420.645350</td>\n",
       "      <td>3414.228475</td>\n",
       "      <td>6171.382800</td>\n",
       "      <td>4840.715500</td>\n",
       "      <td>...</td>\n",
       "      <td>117.208438</td>\n",
       "      <td>424.742500</td>\n",
       "      <td>177.730312</td>\n",
       "      <td>149.772188</td>\n",
       "      <td>212.019940</td>\n",
       "      <td>101.231250</td>\n",
       "      <td>145.074062</td>\n",
       "      <td>66.235312</td>\n",
       "      <td>54.697500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>14876.407000</td>\n",
       "      <td>10152.273000</td>\n",
       "      <td>8605.043800</td>\n",
       "      <td>11248.680000</td>\n",
       "      <td>8093.875000</td>\n",
       "      <td>11222.682000</td>\n",
       "      <td>9939.246200</td>\n",
       "      <td>5917.026300</td>\n",
       "      <td>14144.835000</td>\n",
       "      <td>12307.913000</td>\n",
       "      <td>...</td>\n",
       "      <td>438.383750</td>\n",
       "      <td>902.572500</td>\n",
       "      <td>333.418750</td>\n",
       "      <td>464.930000</td>\n",
       "      <td>702.130950</td>\n",
       "      <td>405.600000</td>\n",
       "      <td>390.890000</td>\n",
       "      <td>197.220000</td>\n",
       "      <td>126.826250</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 2001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           atribut0      atribut1     atribut2      atribut3     atribut4  \\\n",
       "count     62.000000     62.000000    62.000000     62.000000    62.000000   \n",
       "mean    7015.786710   4966.960015  4094.727879   3987.789284  2937.126113   \n",
       "std     3092.970584   2188.890480  1818.080939   2019.086903  1356.932887   \n",
       "min     1914.677500   1383.488600  1269.648700   1186.030400  1166.553600   \n",
       "25%     4877.364700   3408.951150  2763.725900   2648.942875  1890.857125   \n",
       "50%     6274.612500   4738.280700  3890.338100   3451.498200  2666.075600   \n",
       "75%     8712.283175   6455.843200  5008.993750   4738.408950  3563.969325   \n",
       "max    14876.407000  10152.273000  8605.043800  11248.680000  8093.875000   \n",
       "\n",
       "           atribut5     atribut6     atribut7      atribut8      atribut9  \\\n",
       "count     62.000000    62.000000    62.000000     62.000000     62.000000   \n",
       "mean    4705.119302  3588.800323  2872.288631   4680.191160   4039.661953   \n",
       "std     2400.848112  1872.106095  1122.365448   2417.239217   2018.044248   \n",
       "min     1087.750000  1062.697500  1026.477500    995.790000    974.815480   \n",
       "25%     2843.368775  2112.952150  2050.814025   2971.792775   2797.992525   \n",
       "50%     4416.617850  3438.180000  2844.960650   4088.735600   3823.017900   \n",
       "75%     6076.032125  4420.645350  3414.228475   6171.382800   4840.715500   \n",
       "max    11222.682000  9939.246200  5917.026300  14144.835000  12307.913000   \n",
       "\n",
       "       ...  atribut1991  atribut1992  atribut1993  atribut1994  atribut1995  \\\n",
       "count  ...    62.000000    62.000000    62.000000    62.000000    62.000000   \n",
       "mean   ...   100.227903   293.222722   124.653387   133.186935   184.136635   \n",
       "std    ...    78.022712   179.249194    75.535838   101.372557   159.914871   \n",
       "min    ...     5.935000     5.925000     5.923750     5.916250     5.888095   \n",
       "25%    ...    48.409375   161.518125    69.121250    71.637500    85.905059   \n",
       "50%    ...    83.080625   251.883125   114.658125   104.271875   142.578570   \n",
       "75%    ...   117.208438   424.742500   177.730312   149.772188   212.019940   \n",
       "max    ...   438.383750   902.572500   333.418750   464.930000   702.130950   \n",
       "\n",
       "       atribut1996  atribut1997  atribut1998  atribut1999     status  \n",
       "count    62.000000    62.000000    62.000000    62.000000  62.000000  \n",
       "mean     84.118387   114.930000    53.251230    42.965827   0.354839  \n",
       "std      86.182028    88.011866    38.462814    28.395175   0.482370  \n",
       "min       5.878750     5.848750     5.842500     5.816250   0.000000  \n",
       "25%      30.701875    53.881563    27.334375    24.610000   0.000000  \n",
       "50%      56.385625    93.825625    45.358125    34.775000   0.000000  \n",
       "75%     101.231250   145.074062    66.235312    54.697500   1.000000  \n",
       "max     405.600000   390.890000   197.220000   126.826250   1.000000  \n",
       "\n",
       "[8 rows x 2001 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['status'],axis=1)\n",
    "y = data['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_scaler(X_train_, X_test_):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_ = scaler.fit_transform(X_train_)\n",
    "    X_test_ = scaler.transform(X_test_)\n",
    "    return X_train_,X_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_, X_test_ = minmax_scaler(X_train,X_test)\n",
    "X_train = pd.DataFrame(data=X_train_, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(data=X_test_, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduksi Dimensi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# korelasi = data.corr().drop(['status'],axis=1).drop(['status'],axis=0)\n",
    "# korelasi.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F - score score    [2.55784009e+00 1.73585079e+00 3.67395268e+00 ... 2.42752763e+00\n",
      " 2.08849545e-03 9.56459514e-01]\n",
      "F - score p-value  [0.11500158 0.1926744  0.06003501 ... 0.12448029 0.96370108 0.33200741]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "f_score, f_p_value = f_classif(X,y)\n",
    "print('F - score score   ', f_score)\n",
    "print('F - score p-value ', f_p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_subset(s, n_features = 3, n_iter=10):\n",
    "    listSubset = []\n",
    "    for i in range(n_iter):\n",
    "        listSubset.append(random.sample(list(s),n_features))\n",
    "    return listSubset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_redundancy(cor):\n",
    "    korr = []\n",
    "    korr = cor.values\n",
    "    np.fill_diagonal(korr,0)\n",
    "    korr = np.concatenate(korr)\n",
    "    korr = np.unique(korr)\n",
    "    sum_kor = np.sum(korr)\n",
    "    return sum_kor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrmr(X,y,n_features=3,n_iter=10):\n",
    "    subset = random_subset(X.columns,n_features,n_iter)\n",
    "    mrmr_list = []\n",
    "    for i in subset:\n",
    "        korelasi = X[i].corr()\n",
    "        red = count_redundancy(korelasi)\n",
    "        f_score, f_p_value = f_classif(X[i],y)\n",
    "        rel = np.sum(f_score)\n",
    "        mrmr_score = rel - ((1/len(subset))*red)\n",
    "        mrmr_list.append((i,mrmr_score))\n",
    "    return sorted(mrmr_list,key=lambda l:l[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-90306766d53d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtaken_featuresTrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmrmr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtaken_featuresTrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-fdfeb92581fb>\u001b[0m in \u001b[0;36mmrmr\u001b[1;34m(X, y, n_features, n_iter)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmrmr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0msubset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_subset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mmrmr_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mkorelasi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-d531a4a0b791>\u001b[0m in \u001b[0;36mrandom_subset\u001b[1;34m(s, n_features, n_iter)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mlistSubset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mlistSubset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlistSubset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wantannas 14\\appdata\\local\\programs\\python\\python37-32\\lib\\random.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, population, k)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m21\u001b[0m        \u001b[1;31m# size of a small set minus size of an empty list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "taken_featuresTrain = mrmr(X_train,y_train,5000,10)[0][0]\n",
    "taken_featuresTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mrmr = X_train[taken_featuresTrain].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-141f370a9072>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtaken_featuresTest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmrmr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtaken_featuresTest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-fdfeb92581fb>\u001b[0m in \u001b[0;36mmrmr\u001b[1;34m(X, y, n_features, n_iter)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmrmr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0msubset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_subset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mmrmr_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mkorelasi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-d531a4a0b791>\u001b[0m in \u001b[0;36mrandom_subset\u001b[1;34m(s, n_features, n_iter)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mlistSubset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mlistSubset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlistSubset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\wantannas 14\\appdata\\local\\programs\\python\\python37-32\\lib\\random.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, population, k)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m21\u001b[0m        \u001b[1;31m# size of a small set minus size of an empty list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "taken_featuresTest = mrmr(X_test,y_test,5000,10)[0][0]\n",
    "taken_featuresTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_mrmr = X_test[taken_featuresTest].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rfg = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 1000, num = 5)],\n",
    "               'max_features': ['auto', 'log2'],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'bootstrap': [True, False]\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100,\n",
       "                                                    n_jobs...\n",
       "                                                    random_state=None,\n",
       "                                                    verbose=0,\n",
       "                                                    warm_start=False),\n",
       "                   iid='deprecated', n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_features': ['auto', 'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=8, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(estimator=model_rfg,\n",
    "                                   param_distributions=random_grid,\n",
    "                                   n_iter=50,\n",
    "                                   cv=3, \n",
    "                                   verbose=1, \n",
    "                                   random_state=8,\n",
    "                                   n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(X_train_mrmr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params :  {'n_estimators': 800, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}\n",
      "\n",
      "0.674 (+/-0.038) for {'n_estimators': 400, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'auto', 'bootstrap': True}\n",
      "0.674 (+/-0.038) for {'n_estimators': 400, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True}\n",
      "0.634 (+/-0.082) for {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True}\n",
      "0.674 (+/-0.038) for {'n_estimators': 800, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'auto', 'bootstrap': False}\n",
      "0.674 (+/-0.038) for {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'auto', 'bootstrap': True}\n",
      "0.632 (+/-0.104) for {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True}\n",
      "0.653 (+/-0.052) for {'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'bootstrap': True}\n",
      "0.653 (+/-0.052) for {'n_estimators': 800, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'auto', 'bootstrap': True}\n",
      "0.653 (+/-0.052) for {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}\n",
      "0.674 (+/-0.038) for {'n_estimators': 600, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'auto', 'bootstrap': True}\n",
      "0.694 (+/-0.104) for {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'auto', 'bootstrap': True}\n",
      "0.673 (+/-0.069) for {'n_estimators': 600, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'auto', 'bootstrap': False}\n",
      "0.694 (+/-0.017) for {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'auto', 'bootstrap': False}\n",
      "0.673 (+/-0.069) for {'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'auto', 'bootstrap': False}\n",
      "0.653 (+/-0.052) for {'n_estimators': 1000, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}\n",
      "0.674 (+/-0.038) for {'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'auto', 'bootstrap': False}\n",
      "0.653 (+/-0.052) for {'n_estimators': 600, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True}\n",
      "0.653 (+/-0.052) for {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}\n",
      "0.673 (+/-0.069) for {'n_estimators': 600, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'auto', 'bootstrap': False}\n",
      "0.632 (+/-0.104) for {'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'bootstrap': True}\n",
      "0.694 (+/-0.017) for {'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}\n",
      "0.694 (+/-0.017) for {'n_estimators': 1000, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'auto', 'bootstrap': False}\n",
      "0.673 (+/-0.069) for {'n_estimators': 400, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'auto', 'bootstrap': False}\n",
      "0.713 (+/-0.073) for {'n_estimators': 800, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}\n",
      "0.713 (+/-0.073) for {'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}\n",
      "0.653 (+/-0.052) for {'n_estimators': 600, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'auto', 'bootstrap': True}\n",
      "0.653 (+/-0.052) for {'n_estimators': 600, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}\n",
      "0.673 (+/-0.069) for {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}\n",
      "0.713 (+/-0.073) for {'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}\n",
      "0.653 (+/-0.052) for {'n_estimators': 800, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'bootstrap': True}\n",
      "0.692 (+/-0.114) for {'n_estimators': 600, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}\n",
      "0.692 (+/-0.114) for {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'bootstrap': False}\n",
      "0.674 (+/-0.038) for {'n_estimators': 400, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}\n",
      "0.673 (+/-0.069) for {'n_estimators': 600, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'auto', 'bootstrap': False}\n",
      "0.673 (+/-0.069) for {'n_estimators': 600, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'auto', 'bootstrap': False}\n",
      "0.653 (+/-0.052) for {'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True}\n",
      "0.653 (+/-0.052) for {'n_estimators': 600, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': True}\n",
      "0.674 (+/-0.038) for {'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False}\n",
      "0.632 (+/-0.104) for {'n_estimators': 800, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}\n",
      "0.674 (+/-0.038) for {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'auto', 'bootstrap': True}\n",
      "0.674 (+/-0.038) for {'n_estimators': 600, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': True}\n",
      "0.673 (+/-0.069) for {'n_estimators': 600, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}\n",
      "0.674 (+/-0.038) for {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'auto', 'bootstrap': True}\n",
      "0.694 (+/-0.017) for {'n_estimators': 1000, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}\n",
      "0.673 (+/-0.069) for {'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}\n",
      "0.653 (+/-0.052) for {'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': False}\n",
      "0.674 (+/-0.038) for {'n_estimators': 600, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'auto', 'bootstrap': False}\n",
      "0.653 (+/-0.052) for {'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}\n",
      "0.713 (+/-0.073) for {'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2', 'bootstrap': False}\n",
      "0.653 (+/-0.052) for {'n_estimators': 600, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2', 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Params : \",random_search.best_params_)\n",
    "print()\n",
    "means = random_search.cv_results_['mean_test_score']\n",
    "stds = random_search.cv_results_['std_test_score']\n",
    "\n",
    "for mean, std, params in zip(means, stds, random_search.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 800,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'log2',\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 1000, num = 5)],\n",
    "               'max_features': ['log2'],\n",
    "               'min_samples_split': [10],\n",
    "               'min_samples_leaf': [2],\n",
    "               'bootstrap': [False]\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    5.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params :  {'bootstrap': False, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "\n",
      "0.674 (+/-0.038) for {'bootstrap': False, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "0.674 (+/-0.038) for {'bootstrap': False, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 400}\n",
      "0.653 (+/-0.052) for {'bootstrap': False, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 600}\n",
      "0.674 (+/-0.038) for {'bootstrap': False, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 800}\n",
      "0.674 (+/-0.038) for {'bootstrap': False, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator=model_rfg,\n",
    "                                   param_grid=grid_params,\n",
    "                                   cv=3, \n",
    "                                   verbose=1, \n",
    "                                   n_jobs = -1)\n",
    "\n",
    "grid_search.fit(X_train_mrmr, y_train)\n",
    "print(\"Best Params : \",grid_search.best_params_)\n",
    "print()\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "\n",
    "for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='log2',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=10,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train_mrmr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediksi = classifier.predict(X_test_mrmr)\n",
    "prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>status predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    status  status predicted\n",
       "5        1                 0\n",
       "27       0                 0\n",
       "59       1                 0\n",
       "40       0                 0\n",
       "41       1                 0\n",
       "52       0                 0\n",
       "25       0                 0\n",
       "19       1                 1\n",
       "26       0                 0\n",
       "18       0                 0\n",
       "49       1                 0\n",
       "37       0                 0\n",
       "0        0                 0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"status\" : y_test,\n",
    "    \"status predicted\" : prediksi\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6923076923076923"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,prediksi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         8\n",
      "           1       1.00      0.20      0.33         5\n",
      "\n",
      "    accuracy                           0.69        13\n",
      "   macro avg       0.83      0.60      0.57        13\n",
      "weighted avg       0.79      0.69      0.62        13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, prediksi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 921.6x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "aux_df = data[['status']].drop_duplicates().sort_values('status')\n",
    "conf_matrix = confusion_matrix(y_test, prediksi)\n",
    "plt.figure(figsize=(12.8,6))\n",
    "sns.heatmap(conf_matrix, \n",
    "            annot=True,\n",
    "            xticklabels=aux_df['status'].values, \n",
    "            yticklabels=aux_df['status'].values,\n",
    "            cmap=\"Blues\")\n",
    "plt.ylabel('Predicted')\n",
    "plt.xlabel('Actual')\n",
    "plt.title('Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 0],\n",
       "       [4, 1]], dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,prediksi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
